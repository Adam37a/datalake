import os
import sys
import pandas as pd
from sqlalchemy import create_engine
import logging
from pathlib import Path

# Ajouter le dossier parent de 'cleaning' au sys.path
sys.path.append(str(Path(__file__).resolve().parents[1]))

# Imports des fonctions de nettoyage
from cleaning.cleaning_glassdoor import get_cleaned_glassdoor_df
from cleaning.google_trendsClean import get_cleaned_google_trends_df
from cleaning.github_clean import get_cleaned_github_trends_df
from cleaning.adzuna_clean import get_cleaned_adzuna_df

# === Config de logging ===
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# === Param√®tres de connexion PostgreSQL ===
DB_NAME = "postgres"
DB_USER = "postgres"
DB_PASS = "admin"
DB_HOST = "localhost"
DB_PORT = "5432"

# === R√©pertoire des donn√©es brutes ===
BASE_DIR = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "..", "..", "data", "raw")
)

EXCLUDED_SOURCES = {"stack_overflow"}

# === Connexion SQLAlchemy ===
engine = create_engine(f"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}")

def normalize_table_name(name: str) -> str:
    """
    Normalise le nom de la table (minuscules, remplace espaces et tirets)
    """
    return name.lower().replace("-", "_").replace(" ", "_")

def load_data_to_postgres():
    # ‚úÖ Cas sp√©cial : Glassdoor
    try:
        logger.info("üßΩ Nettoyage des donn√©es Glassdoor...")
        df_glassdoor = get_cleaned_glassdoor_df()
        df_glassdoor.to_sql("glassdoor", con=engine, if_exists="append", index=False)
        logger.info("‚úÖ Donn√©es Glassdoor ins√©r√©es (avec enrichissement des comp√©tences)")
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage/insertion Glassdoor : {e}")

    # ‚úÖ Cas sp√©cial : Google Trends
    try:
        logger.info("üßΩ Nettoyage des donn√©es Google Trends...")
        df_google_trends = get_cleaned_google_trends_df()
        df_google_trends.to_sql("google_trends", con=engine, if_exists="append", index=False)
        logger.info("‚úÖ Donn√©es Google Trends ins√©r√©es (pays europ√©ens uniquement)")
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage/insertion Google Trends : {e}")

    # ‚úÖ Cas sp√©cial : GitHub Trends
    try:
        logger.info("üßΩ Nettoyage des donn√©es GitHub Trends...")
        df_github_trends = get_cleaned_github_trends_df()
        df_github_trends.to_sql("github_trend", con=engine, if_exists="append", index=False)
        logger.info("‚úÖ Donn√©es GitHub Trends ins√©r√©es (avec traduction en anglais)")
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage/insertion GitHub Trends : {e}")

    # ‚úÖ Cas sp√©cial : Adzuna
    try:
        logger.info("üßΩ Nettoyage des donn√©es Adzuna...")
        df_adzuna = get_cleaned_adzuna_df()
        df_adzuna.to_sql("adzuna", con=engine, if_exists="append", index=False)
        logger.info("‚úÖ Donn√©es Adzuna ins√©r√©es (pays, dates et salaires)")
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage/insertion Adzuna : {e}")

    # üîÅ Parcours des autres sources
    for source in os.listdir(BASE_DIR):
        normalized_source = source.lower()
        if normalized_source in EXCLUDED_SOURCES or normalized_source in {"glassdoor", "google trends", "github_trend", "adzuna"}:
            logger.info(f"‚è© Source ignor√©e : {source}")
            continue

        source_path = os.path.join(BASE_DIR, source)
        if not os.path.isdir(source_path):
            continue

        table_name = normalize_table_name(source)
        logger.info(f"üì¶ Traitement de la source : {source} ‚Üí Table : {table_name}")

        for file in os.listdir(source_path):
            file_path = os.path.join(source_path, file)
            try:
                if file.endswith(".csv"):
                    df = pd.read_csv(file_path, encoding="utf-8")
                elif file.endswith(".json"):
                    df = pd.read_json(file_path, lines=False)
                else:
                    logger.warning(f"‚ö†Ô∏è Fichier ignor√© (format non support√©) : {file}")
                    continue

                logger.info(f"üìÑ Chargement de {file} ({len(df)} lignes)")

                df.to_sql(table_name, con=engine, if_exists='append', index=False)
                logger.info(f"‚úÖ Donn√©es ins√©r√©es dans la table : {table_name}")
            except Exception as e:
                logger.error(f"‚ùå Erreur d'insertion pour {file} : {e}")

if __name__ == "__main__":
    load_data_to_postgres()
